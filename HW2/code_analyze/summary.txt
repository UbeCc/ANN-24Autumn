########################
# Additional Files
########################
# .DS_Store

########################
# Filled Code
########################
# ../codes/cnn/model.py:1
        super(BatchNorm2d, self).__init__()
        # input: [batch_size, num_feature_map, height, width]

# ../codes/cnn/model.py:2
        # input: [batch_size, num_feature_map, height, width]

# ../codes/cnn/model.py:3

# ../codes/cnn/model.py:4

# ../codes/mlp/model.py:1

# ../codes/mlp/model.py:2

# ../codes/mlp/model.py:3

# ../codes/mlp/model.py:4


########################
# References
########################

########################
# Other Modifications
########################
# _codes/cnn/main.py -> ../codes/cnn/main.py
# 13 - from load_data import load_cifar_4d
# 13 ?                                  ^
# 13 + from load_data import load_cifar_2d
# 13 ?                                  ^
# 105 -         X_train, X_test, y_train, y_test = load_cifar_4d(args.data_dir)
# 105 ?                                                       ^
# 105 +         X_train, X_test, y_train, y_test = load_cifar_2d(args.data_dir)
# 105 ?                                                       ^
# 108 -         cnn_model = Model(drop_rate=args.drop_rate)
# 108 ?         ^^^                         -----
# 108 +         mlp_model = Model(drop_rate=drop_rate)
# 108 ?         ^^^
# 109 -         cnn_model.to(device)
# 109 ?         ^^^
# 109 +         mlp_model.to(device)
# 109 ?         ^^^
# 110 -         print(cnn_model)
# 110 ?               ^^^
# 110 +         print(mlp_model)
# 110 ?               ^^^
# 111 -         optimizer = optim.Adam(cnn_model.parameters(), lr=args.learning_rate)
# 111 ?                                ^^^
# 111 +         optimizer = optim.Adam(mlp_model.parameters(), lr=args.learning_rate)
# 111 ?                                ^^^
# 115 -         # 	cnn_model = torch.load(model_path)
# 115 ?           	^^^
# 115 +         # 	mlp_model = torch.load(model_path)
# 115 ?           	^^^
# 121 -             train_acc, train_loss = train_epoch(cnn_model, X_train, y_train, optimizer)
# 121 ?                                                 ^^^
# 121 +             train_acc, train_loss = train_epoch(mlp_model, X_train, y_train, optimizer)
# 121 ?                                                 ^^^
# 124 -             val_acc, val_loss = valid_epoch(cnn_model, X_val, y_val)
# 124 ?                                             ^^^
# 124 +             val_acc, val_loss = valid_epoch(mlp_model, X_val, y_val)
# 124 ?                                             ^^^
# 129 -                 test_acc, test_loss = valid_epoch(cnn_model, X_test, y_test)
# 129 ?                                                   ^^^
# 129 +                 test_acc, test_loss = valid_epoch(mlp_model, X_test, y_test)
# 129 ?                                                   ^^^
# 130 -                 with open(os.path.join(args.train_dir, 'checkpoint_{}.pth.tar'.format(epoch)), 'wb') as fout:
# 130 +                 # with open(os.path.join(args.train_dir, 'checkpoint_{}.pth.tar'.format(epoch)), 'wb') as fout:
# 130 ?                ++
# 131 -                     torch.save(cnn_model, fout)
# 131 ?                  ^^^           ^^^
# 131 +                 # 	torch.save(mlp_model, fout)
# 131 ?                 + ^           ^^^
# 132 -                 with open(os.path.join(args.train_dir, 'checkpoint_0.pth.tar'), 'wb') as fout:
# 132 +                 # with open(os.path.join(args.train_dir, 'checkpoint_0.pth.tar'), 'wb') as fout:
# 132 ?                ++
# 133 -                     torch.save(cnn_model, fout)
# 133 ?                  ^^^           ^^^
# 133 +                 # 	torch.save(mlp_model, fout)
# 133 ?                 + ^           ^^^
# 154 -         cnn_model = Model()
# 154 ?         ^^^
# 154 +         mlp_model = Model()
# 154 ?         ^^^
# 155 -         cnn_model.to(device)
# 155 ?         ^^^
# 155 +         mlp_model.to(device)
# 155 ?         ^^^
# 158 -             cnn_model = torch.load(model_path)
# 158 ?             ^^^
# 158 +             mlp_model = torch.load(model_path)
# 158 ?             ^^^
# 160 -         X_train, X_test, y_train, y_test = load_cifar_4d(args.data_dir)
# 160 ?                                                       ^
# 160 +         X_train, X_test, y_train, y_test = load_cifar_2d(args.data_dir)
# 160 ?                                                       ^
# 164 -             test_image = X_test[i].reshape((1, 3, 32, 32))
# 164 ?                                                 ^   ^
# 164 +             test_image = X_test[i].reshape((1, 3 * 32 * 32))
# 164 ?                                                 ^^   ^^
# 165 -             result = inference(cnn_model, test_image)[0]
# 165 ?                                ^^^
# 165 +             result = inference(mlp_model, test_image)[0]
# 165 ?                                ^^^
# _codes/cnn/model.py -> ../codes/cnn/model.py
# 7 - class BatchNorm1d(nn.Module):
# 7 ?                ^
# 7 + class BatchNorm2d(nn.Module):
# 7 ?                ^
# 47 -     def forward(self, x, y=None):
# 47 +     def forward(self, x, y=None):
# 47 ?                                  +
# _codes/mlp/main.py -> ../codes/mlp/main.py
# 108 -         mlp_model = Model(drop_rate=drop_rate)
# 108 +         mlp_model = Model(drop_rate=args.drop_rate)
# 108 ?                                     +++++

