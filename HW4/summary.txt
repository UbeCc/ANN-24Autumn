########################
# Additional Files
########################
# __pycache__
# report
# inception
# runs
# results
# data

########################
# Filled Code
########################
# ../codes/GAN/trainer.py:1
        D_r = self._netD(real_imgs)
        loss_D_real = BCE_criterion(D_r, torch.ones_like(D_r, device=self._device))
        D_x = D_r.mean().item()
        loss_D_real.backward()

# ../codes/GAN/trainer.py:2
        D_f = self._netD(fake_imgs)
        loss_D_fake = BCE_criterion(D_f, torch.zeros_like(D_f, device=self._device))
        D_G_z1 = D_f.mean().item()
        loss_D_fake.backward(retain_graph=True)

# ../codes/GAN/trainer.py:3
        D_f_2 = self._netD(fake_imgs)
        loss_G = BCE_criterion(D_f_2, torch.ones_like(D_f_2, device=self._device))
        D_G_z2 = D_f_2.mean().item()

# ../codes/GAN/GAN.py:1
            self.decoder = nn.Sequential(
                # state size: (latent_dim) x 1 x 1
                nn.ConvTranspose2d(latent_dim, hidden_dim * 4, kernel_size=4, stride=1, padding=0, bias=True),
                nn.BatchNorm2d(hidden_dim * 4) if not withoutNorm else nn.Identity(),
                nn.ReLU(False) if onlyReLU else nn.LeakyReLU(0.2, inplace=True),
                # state size: (hidden_dim*4) x 4 x 4
                nn.ConvTranspose2d(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1, bias=True),
                nn.BatchNorm2d(hidden_dim * 2) if not withoutNorm else nn.Identity(),
                nn.ReLU(False) if onlyReLU else nn.LeakyReLU(0.2, inplace=True),
                # state size: (hidden_dim*2) x 8 x 8
                nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=4, stride=2, padding=1, bias=True),
                nn.BatchNorm2d(hidden_dim) if not withoutNorm else nn.Identity(),
                nn.ReLU(False) if onlyReLU else nn.LeakyReLU(0.2, inplace=True),
                # state size: (hidden_dim) x 16 x 16
                nn.ConvTranspose2d(hidden_dim, num_channels, kernel_size=4, stride=2, padding=1, bias=False),
                nn.Tanh()
                # state size: (num_channels) x 32 x 32
            )


########################
# References
########################

########################
# Other Modifications
########################
# _codes/GAN/pytorch_fid/inception.py -> ../codes/GAN/pytorch_fid/inception.py
# 7 - try:
# 8 -     from torchvision.models.utils import load_state_dict_from_url
# 9 - except ImportError:
# 10 -     from torch.utils.model_zoo import load_url as load_state_dict_from_url
# 10 ? ----
# 7 + from torch.utils.model_zoo import load_url as load_state_dict_from_url
# _codes/GAN/trainer.py -> ../codes/GAN/trainer.py
# 11 + import wandb
# 12 +
# 13 + USE_WANDB = False
# 33 +         self.num_channels = 1
# 110 +
# 111 +                 if USE_WANDB:
# 112 +                     wandb.log({
# 113 +                         "discriminator_loss": errD.item(),
# 114 +                         "generator_loss": errG.item(),
# 115 +                         "D(x)": D_x.item(),
# 116 +                         "D(G(z1))": D_G_z1.item(),
# 117 +                         "D(G(z2))": D_G_z2.item()
# 118 +                     }, step=i)
# 119 +
# 109 -                 save_image(imgs, os.path.join(dirname, "samples.png"))
# 109 ?                                                                       -
# 126 +                 save_image(imgs, os.path.join(dirname, "samples.png"))
# _codes/GAN/GAN.py -> ../codes/GAN/GAN.py
# 5 + onlyReLU = False
# 6 + withoutNorm = False
# 7 +
# 7 -     if classname.find('Conv') != -1:
# 10 +     if classname.find('Conv') != -1 or classname.find('Linear') != -1:
# 13 - def get_generator(num_channels, latent_dim, hidden_dim, device):
# 16 + def get_generator(num_channels, latent_dim, hidden_dim, device, arch="cnn"):
# 16 ?                                                               ++++++++++++
# 14 -     model = Generator(num_channels, latent_dim, hidden_dim).to(device)
# 17 +     model = Generator(num_channels, latent_dim, hidden_dim, arch).to(device)
# 17 ?                                                           ++++++
# 18 - def get_discriminator(num_channels, hidden_dim, device):
# 21 + def get_discriminator(num_channels, hidden_dim, device, arch="cnn"):
# 21 ?                                                       ++++++++++++
# 19 -     model = Discriminator(num_channels, hidden_dim).to(device)
# 22 +     model = Discriminator(num_channels, hidden_dim, arch).to(device)
# 22 ?                                                   ++++++
# 24 -     def __init__(self, num_channels, latent_dim, hidden_dim):
# 27 +     def __init__(self, num_channels, latent_dim, hidden_dim, arch="cnn"):
# 27 ?                                                            ++++++++++++
# 29 +         self.arch = arch
# 33 +         self.output_dim = num_channels * 32 * 32  # For mlp output reshape
# 35 +         if arch == "cnn":
# 56 +         elif arch == "mlp":
# 57 +             self.decoder = nn.Sequential(
# 58 +                 nn.Linear(latent_dim, hidden_dim * 4),
# 59 +                 nn.BatchNorm1d(hidden_dim * 4) if not withoutNorm else nn.Identity(),
# 60 +                 nn.ReLU() if onlyReLU else nn.LeakyReLU(0.2),
# 61 +                 nn.Linear(hidden_dim * 4, hidden_dim * 2),
# 62 +                 nn.BatchNorm1d(hidden_dim * 2) if not withoutNorm else nn.Identity(),
# 63 +                 nn.ReLU() if onlyReLU else nn.LeakyReLU(0.2),
# 64 +                 nn.Linear(hidden_dim * 2, hidden_dim),
# 65 +                 nn.BatchNorm1d(hidden_dim) if not withoutNorm else nn.Identity(),
# 66 +                 nn.ReLU() if onlyReLU else nn.LeakyReLU(0.2),
# 67 +                 nn.Linear(hidden_dim, self.output_dim),
# 68 +                 nn.Tanh()
# 69 +             )
# 37 -         '''
# 38 -         *   Arguments:
# 39 -             *   z (torch.FloatTensor): [batch_size, latent_dim, 1, 1]
# 40 -         '''
# 73 +         if self.arch == "cnn":
# 42 -         return self.decoder(z)
# 74 +             return self.decoder(z)
# 74 ? ++++
# 75 +         elif self.arch == "mlp":
# 76 +             z = z.squeeze(-1).squeeze(-1)
# 77 +             out = self.decoder(z)
# 78 +             return out.view(-1, self.num_channels, 32, 32)
# 60 -
# 96 +
# 62 -     def __init__(self, num_channels, hidden_dim):
# 98 +     def __init__(self, num_channels, hidden_dim, arch="cnn"):
# 98 ?                                                ++++++++++++
# 100 +         self.arch = arch
# 103 +         self.input_dim = num_channels * 32 * 32  # For mlp input reshape
# 104 +
# 105 +         if arch == "cnn":
# 66 -         self.clf = nn.Sequential(
# 106 +             self.clf = nn.Sequential(
# 106 ? ++++
# 67 -             # input is (num_channels) x 32 x 32
# 68 -             nn.Conv2d(num_channels, hidden_dim, 4, 2, 1, bias=False),
# 68 ?                                                               ^^^^
# 107 +                 nn.Conv2d(num_channels, hidden_dim, 4, 2, 1, bias=True),
# 107 ? ++++                                                              ^^^
# 69 -             nn.LeakyReLU(0.2, inplace=True),
# 108 +                 nn.LeakyReLU(0.2, inplace=True),
# 108 ? ++++
# 70 -             # state size. (hidden_dim) x 16 x 16
# 71 -             nn.Conv2d(hidden_dim, hidden_dim * 2, 4, 2, 1, bias=False),
# 71 ?                                                                 ^^^^
# 109 +                 nn.Conv2d(hidden_dim, hidden_dim * 2, 4, 2, 1, bias=True),
# 109 ? ++++                                                                ^^^
# 72 -             nn.BatchNorm2d(hidden_dim * 2),
# 110 +                 nn.BatchNorm2d(hidden_dim * 2) if not withoutNorm else nn.Identity(),
# 73 -             nn.LeakyReLU(0.2, inplace=True),
# 111 +                 nn.LeakyReLU(0.2, inplace=True),
# 111 ? ++++
# 74 -             # state size. (hidden_dim*2) x 8 x 8
# 75 -             nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 4, 2, 1, bias=False),
# 75 ?                                                                     ^^^^
# 112 +                 nn.Conv2d(hidden_dim * 2, hidden_dim * 4, 4, 2, 1, bias=True),
# 112 ? ++++                                                                    ^^^
# 76 -             nn.BatchNorm2d(hidden_dim * 4),
# 113 +                 nn.BatchNorm2d(hidden_dim * 4) if not withoutNorm else nn.Identity(),
# 77 -             nn.LeakyReLU(0.2, inplace=True),
# 114 +                 nn.LeakyReLU(0.2, inplace=True),
# 114 ? ++++
# 78 -             # state size. (hidden_dim*4) x 4 x 4
# 79 -             nn.Conv2d(hidden_dim * 4, 1, 4, 1, 0, bias=False),
# 79 ?                                                        ^^^^
# 115 +                 nn.Conv2d(hidden_dim * 4, 1, 4, 1, 0, bias=True),
# 115 ? ++++                                                       ^^^
# 80 -             nn.Sigmoid()
# 116 +                 nn.Sigmoid()
# 116 ? ++++
# 81 -         )
# 117 +             )
# 117 ? ++++
# 118 +         elif arch == "mlp":
# 119 +             self.clf = nn.Sequential(
# 120 +                 nn.Linear(self.input_dim, hidden_dim * 4),
# 121 +                 nn.LeakyReLU(0.2),
# 122 +                 nn.Linear(hidden_dim * 4, hidden_dim * 2),
# 123 +                 nn.BatchNorm1d(hidden_dim * 2) if not withoutNorm else nn.Identity(),
# 124 +                 nn.LeakyReLU(0.2),
# 125 +                 nn.Linear(hidden_dim * 2, hidden_dim),
# 126 +                 nn.BatchNorm1d(hidden_dim) if not withoutNorm else nn.Identity(),
# 127 +                 nn.LeakyReLU(0.2),
# 128 +                 nn.Linear(hidden_dim, 1),
# 129 +                 nn.Sigmoid()
# 130 +             )
# 133 +         if self.arch == "cnn":
# 84 -         return self.clf(x).view(-1, 1).squeeze(1)
# 134 +             return self.clf(x).view(-1, 1).squeeze(1)
# 134 ? ++++
# 135 +         elif self.arch == "mlp":
# 136 +             x = x.view(x.size(0), -1)  # Flatten the input for mlp
# 137 +             return self.clf(x).view(-1, 1).squeeze(1)
# 101 -         return os.path.split(path)[0]
# 101 ?                                      -
# 154 +         return os.path.split(path)[0]
# _codes/GAN/main.py -> ../codes/GAN/main.py
# 1 + from torchvision.utils import make_grid
# 2 + from torchvision.utils import save_image
# 3 +
# 4 + import time
# 14 -     parser = argparse.ArgumentParser()
# 18 +     parser = argparse.ArgumentParser()
# 18 ?                                       ++++
# 33 +
# 34 +     parser.add_argument('--run_id', type=str, default='default')
# 35 +     parser.add_argument('--tag', type=str, default='default')
# 36 +     parser.add_argument('--interpolation', action='store_true')
# 37 +     parser.add_argument('--arch', default='cnn', type=str)
# 31 -     config = 'z-{}_batch-{}_num-train-steps-{}'.format(args.latent_dim, args.batch_size, args.num_training_steps)
# 40 +     timestamp = time.strftime('%Y%m%d-%H%M%S', time.localtime())
# 41 +     config = '{}-ldim{}-bsize{}-steps{}-ghidden{}-dhidden{}-{}-{}'.format(
# 42 +         args.arch,
# 43 +         args.latent_dim,
# 44 +         args.batch_size,
# 45 +         args.num_training_steps,
# 46 +         args.generator_hidden_dim,
# 47 +         args.discriminator_hidden_dim,
# 48 +         args.tag,
# 49 +         timestamp
# 50 +     )
# 51 +
# 52 +     if not args.do_train:
# 53 +         args.ckpt_dir = os.path.join(args.ckpt_dir, args.run_id)
# 54 +         config = args.run_id
# 55 +     else:
# 32 -     args.ckpt_dir = os.path.join(args.ckpt_dir, config)
# 56 +         args.ckpt_dir = os.path.join(args.ckpt_dir, config)
# 56 ? ++++
# 58 +
# 59 +
# 62 +     num_channels = 1
# 63 +
# 37 -     netG = GAN.get_generator(1, args.latent_dim, args.generator_hidden_dim, device)
# 37 ?                              ^
# 65 +     netG = GAN.get_generator(num_channels, args.latent_dim, args.generator_hidden_dim, device, args.arch)
# 65 ?                              ^^^^^^^^^^^^                                                    +++++++++++
# 38 -     netD = GAN.get_discriminator(1, args.discriminator_hidden_dim, device)
# 38 ?                                  ^
# 66 +     netD = GAN.get_discriminator(num_channels, args.discriminator_hidden_dim, device, args.arch)
# 66 ?                                  ^^^^^^^^^^^^                                       +++++++++++
# 46 -
# 74 +                 # 64, 1, 32, 32
# 75 +     print("ckpt dir:", args.ckpt_dir)
# 76 +     print("folders:", str(max(int(step) for step in os.listdir(args.ckpt_dir) if step.isdigit())))
# 47 -     restore_ckpt_path = os.path.join(args.ckpt_dir, str(max(int(step) for step in os.listdir(args.ckpt_dir))))
# 77 +     restore_ckpt_path = os.path.join(args.ckpt_dir, str(max(int(step) for step in os.listdir(args.ckpt_dir) if step.isdigit())))
# 77 ?                                                                                                            ++++++++++++++++++
# 50 -     num_samples = 3000
# 80 +     num_samples = 3000
# 80 ?                       ++++
# 81 +     os.makedirs(f"results/config", exist_ok=True)
# 51 -     real_imgs = None
# 52 -     real_dl = iter(dataset.training_loader)
# 53 -     while real_imgs is None or real_imgs.size(0) < num_samples:
# 54 -         imgs = next(real_dl)
# 55 -         if real_imgs is None:
# 56 -             real_imgs = imgs[0]
# 57 -         else:
# 58 -             real_imgs = torch.cat((real_imgs, imgs[0]), 0)
# 59 -     real_imgs = real_imgs[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 83 +     if args.interpolation:
# 61 -     with torch.no_grad():
# 84 +         with torch.no_grad():
# 84 ? ++++
# 85 +             imgs = None
# 86 +             for i in range(20): # 20 interpolations
# 87 +                 points, left, right = 10, 0.0, 1.0
# 88 +                 lefthand = torch.randn(1, netG.latent_dim, 1, device=device)
# 89 +                 righthand = torch.randn(1, netG.latent_dim, 1, device=device)
# 90 +                 weights = torch.linspace(left, right, points, device=device)
# 91 +                 vecs = torch.lerp(lefthand, righthand, weights)
# 92 +                 vecs = vecs.transpose(1, 2).view(points, netG.latent_dim, 1, 1)
# 93 +
# 94 +                 if imgs is None:
# 95 +                     imgs = netG.forward(vecs)
# 96 +                 else:
# 97 +                     imgs = torch.cat((imgs, netG.forward(vecs)), 0)
# 98 +             imgs = make_grid(imgs, nrow=points, pad_value=0) * 0.5 + 0.5
# 99 +             save_image(imgs,"results/interpolation.png")
# 100 +             exit()
# 101 +
# 102 +     for i in range(5):
# 103 +         fids = []
# 104 +         real_dl = iter(dataset.training_loader)
# 62 -         samples = None
# 62 ?         ^  ^^^
# 105 +         real_imgs = None
# 105 ?         ^^ +++ ^
# 63 -         while samples is None or samples.size(0) < num_samples:
# 63 ?               ^  ^^^             ^  ^^^
# 106 +         while real_imgs is None or real_imgs.size(0) < num_samples:
# 106 ?               ^^ +++ ^             ^^ +++ ^
# 64 -             imgs = netG.forward(torch.randn(args.batch_size, netG.latent_dim, 1, 1, device=device))
# 107 +             imgs = next(real_dl)
# 65 -             if samples is None:
# 65 ?                ^  ^^^
# 108 +             if real_imgs is None:
# 108 ?                ^^ +++ ^
# 66 -                 samples = imgs
# 66 ?                 ^  ^^^
# 109 +                 real_imgs = imgs[0]
# 109 ?                 ^^ +++ ^        +++
# 68 -                 samples = torch.cat((samples, imgs), 0)
# 68 ?                 ^  ^^^               ^  ^^^
# 111 +                 real_imgs = torch.cat((real_imgs, imgs[0]), 0)
# 111 ?                 ^^ +++ ^               ^^ +++ ^       +++
# 69 -     samples = samples[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 69 ?     ^  ^^^    ^  ^^^
# 112 +         real_imgs = real_imgs[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 112 ?     ^^^^^^ +++ ^    ^^ +++ ^
# 70 -     samples = samples.cpu()
# 114 +         with torch.no_grad():
# 115 +             samples = None
# 116 +             while samples is None or samples.size(0) < num_samples:
# 117 +                 noise = torch.randn(args.batch_size, netG.latent_dim, device=device)
# 118 +                 if args.arch == "mlp":
# 119 +                     imgs = netG(noise)
# 120 +                 else:
# 121 +                     imgs = netG(noise.unsqueeze(2).unsqueeze(3))
# 122 +                 if samples is None:
# 123 +                     samples = imgs
# 124 +                 else:
# 125 +                     samples = torch.cat((samples, imgs), 0)
# 126 +
# 127 +         samples = samples[:num_samples].expand(-1, 3, -1, -1) * 0.5 + 0.5
# 128 +         samples = samples.cpu()
# 129 +
# 130 +         imgs = make_grid(samples, nrow=10, pad_value=0) *0.5 + 0.5
# 131 +         save_image(imgs,f"results/config/samples-{config}-{i}.png")
# 132 +
# 72 -     fid = fid_score.calculate_fid_given_images(real_imgs, samples, args.batch_size, device)
# 133 +         fid = fid_score.calculate_fid_given_images(real_imgs, samples, args.batch_size, device)
# 133 ? ++++
# 73 -     tb_writer.add_scalar('fid', fid)
# 134 +         tb_writer.add_scalar('fid', fid)
# 134 ? ++++
# 74 -     print("FID score: {:.3f}".format(fid), flush=True)
# 135 +         print("FID score: {:.3f}".format(fid), flush=True)
# 135 ? ++++                                                      +
# 136 +         fids.append(fid)
# 137 +
# 138 +     with open(f"results/{config}/fids.txt", "w") as f:
# 139 +         f.write(str(fids))

